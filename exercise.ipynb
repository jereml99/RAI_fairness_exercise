{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAI Exercise 1: Algorithmic Fairness ‚öñÔ∏è     \n",
    "\n",
    "# Important information\n",
    "This exercise is part of the RAI course (02517 - **Responsible AI: Algorithmic Fairness and Explainability**) at the Technical University of Denmark (DTU). You can find more details about the course [here](https://kurser.dtu.dk/course/02517). This specific version is for the Fall 2024 semester.\n",
    "\n",
    "If you have any questions related to this notebook, feel free to reach out to Nina Weng at *ninwe@dtu.dk*.\n",
    "\n",
    "**Credits**:  \n",
    "We thank:\n",
    "* NIH dataset team for collecting such dataset [link to the paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf);\n",
    "* Authors from [this paper](https://link.springer.com/chapter/10.1007/978-3-031-45249-9_14) for providing the splits;\n",
    "* [Memes generator webpage imgflip](https://imgflip.com/) for all the excellent Memes template.\n",
    "\n",
    "\n",
    "# PART 1: Fairness assessment and Bias mitigation using Fairlearn\n",
    "\n",
    "The goal of this exercise is to learn how to use [Fairlearn](https://fairlearn.org/) to approach basic fairness assessments and apply post-processing bias mitigation methods. \n",
    "\n",
    "Fairlearn is an open-source Python package originally developed by Microsoft Research. Since 2021, it has become completely community-driven. For more information about Fairlearn, you can visit [this page]((https://fairlearn.org/v0.10/about/index.html)). \n",
    "\n",
    "Although Fairlearn is likely the most well-developed package targeting fairness issues, it has its limitations. The most notable limitation, that might need to be mentioned at very beginning for this exercise, is that Fairlearn is primarily designed for tabular data ([this page](https://fairlearn.org/main/faq.html) under question: *Does Fairlearn work for image and text data?*). Therefore, when working with other types of data, such as image data, unexpected issues may arise. Fortunate enough, there are workarounds for most of these issues, which will be discussed later in this exercise.\n",
    "\n",
    "While Fairlearn is a good resource and offers an easy approach for learning fairness concepts and handling lighter tasks, it may not be the best solution for researchers working extensively in this area. Keep that in mind :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Objective of this Exercise (PART 1)\n",
    "By the end of this exercise, you should be able to:\n",
    "\n",
    "* Assess fairness using Fairlearn with provided predictions/probabilities and target labels. This includes calculating metrics, generating ROC curves, and interpreting their meaning.\n",
    "* Apply post-processing bias mitigation techniques using Fairlearn, and clearly understand and explain the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./support4notebook/getstarted.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset: Chest X-ray and lung/heart related disease\n",
    "\n",
    "\n",
    "In this exercise, we will use a chest X-ray dataset and a basic deep learning model as the setup. It requires the following:\n",
    "\n",
    "* Download the dataset/metadata/pretrained ResNet model. Note that in this exercise, we only use part of the data, and details are listed below. The full dataset can be found [here](https://nihcc.app.box.com/v/ChestXray-NIHCC). (For students in the class, you can find a download link on DTU Learn. For those not in the class, you can find the pre-processing scripts in [this repository](https://github.com/nina-weng/detecting_causes_of_gender_bias_chest_xrays).)\n",
    "* After downloading the materials, put the `NIH_train_val_test_rs0_f50.csv` under `./datafiles/`; and `nih_pneumothorax.pth` under `./pretrained_model/`.\n",
    "* Prepare your virtual environment: \n",
    "`conda env create -f env.yml`\n",
    "\n",
    "\n",
    "### Chest xray samples\n",
    "We use [NIH chest xray dataset](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community) in this exercise. Let‚Äôs take a closer look at the dataset. </br>\n",
    "\n",
    "This dataset contains 108,948 images from 32,717 patients, each labeled with one of 14 types of lung or heart-related diseases/symptoms. For detailed information on each disease, you can find explanations [here](https://nihcc.app.box.com/v/ChestXray-NIHCC/file/220660789610).\n",
    "\n",
    "For simplicity, we will use only one sample per patient and preprocess the images to a size of 224x224. Both the dataset and the metadata (in CSV format) are available. The dataset split is also specified in the metadata under the column 'split'.\n",
    "\n",
    "Note: The split was designed for a different task, which required a larger test set than usual. As a result (as you‚Äôll notice), the test set is relatively large (around 8k for training, 2k for validation, and 8k for testing). If you find that the mitigation or prediction process takes too long, feel free to downsample the test set. Just ensure you validate that the proportions of samples across different sensitive groups and disease labels remain roughly consistent with the original test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fairlearn.metrics import MetricFrame, selection_rate,false_positive_rate,true_positive_rate,false_negative_rate,true_negative_rate\n",
    "\n",
    "\n",
    "#\n",
    "from train.model import ResNet\n",
    "from train.prediction import validate\n",
    "from analysis.plot import plot_roc_simple\n",
    "from analysis.tools import from_loader_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change this to your data directory\n",
    "datadir = \"datafiles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look of some samples, with filter query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pth = datadir + '/NIH_part/'\n",
    "metadata_csv ='./datafiles/NIH_train_val_test_rs0_f50.csv'\n",
    "metadata = pd.read_csv(metadata_csv)\n",
    "\n",
    "# display(metadata.head(5))\n",
    "\n",
    "# randomly choose some samples from PAD-UFES-20\n",
    "def show_random_images(datadir,metadata,seed=None,filter_str=None,num_sample=5):\n",
    "    fig = plt.figure(figsize=(num_sample*3, 3),dpi=200)\n",
    "    files = os.listdir(datadir)\n",
    "    if filter_str:\n",
    "        metadata = metadata.query(filter_str)\n",
    "        # display(metadata.head(5))\n",
    "    if seed is not None:\n",
    "        random_sample = metadata.sample(n=num_sample, random_state=seed)\n",
    "    else: random_sample = metadata.sample(n=num_sample)\n",
    "    \n",
    "    for i in range(len(random_sample)):\n",
    "        row = random_sample.iloc[i]\n",
    "        disease = row['Pneumothorax']\n",
    "        sex = row['Patient Gender']\n",
    "\n",
    "        img = mpimg.imread(datadir + row['Image Index'])\n",
    "        ax = fig.add_subplot(1, len(random_sample), i + 1)\n",
    "        # add diagnosis as subtitle\n",
    "        ax.set_title(f'{disease=},{sex=}')\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(f'{filter_str}')\n",
    "    plt.show()\n",
    "\n",
    "show_random_images(dataset_pth,metadata=metadata,seed=42,filter_str='Pneumothorax==1 and `Patient Gender`==\"F\"',num_sample=5)\n",
    "show_random_images(dataset_pth,metadata=metadata,seed=42,filter_str='Pneumothorax==1 and `Patient Gender`==\"M\"',num_sample=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistics\n",
    "\n",
    "We can also take a look at the distribution of some sensitive attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_by_value(metadata, column_name):\n",
    "    if isinstance(column_name, str):\n",
    "        nan_count = metadata[column_name].isna().sum()\n",
    "        nan_series = pd.Series([nan_count], index=['NaN'])\n",
    "        counts_ = metadata[column_name].value_counts().sort_index()\n",
    "        counts_with_nan = pd.concat([counts_, nan_series])\n",
    "\n",
    "        counts_with_nan.plot(kind='bar',title='Distribution of {}'.format(column_name))\n",
    "        plt.ylabel('count')\n",
    "    elif isinstance(column_name, list):\n",
    "        fig, axes = plt.subplots( 1, len(column_name), figsize=( len(column_name)*4,3),dpi=200)\n",
    "        for i,col in enumerate(column_name):\n",
    "            nan_count = metadata[col].isna().sum()\n",
    "            nan_series = pd.Series([nan_count], index=['NaN'])\n",
    "            counts_ = metadata[col].value_counts().sort_index()\n",
    "            counts_with_nan = pd.concat([counts_, nan_series])\n",
    "\n",
    "            counts_with_nan.plot(kind='bar',title='Distribution of {}'.format(col),ax=axes[i])\n",
    "            axes[i].set_ylabel('count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "metadata['age_range'] = pd.cut(metadata['Patient Age'], bins=[0,10,20,30,40,50,60,70,80,90,100], right=False)\n",
    "plot_distribution_by_value(metadata, ['age_range','Patient Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that, for this specific split, we maintain an equal number of male and female samples. This balance is consistent across all three splits: training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÉ Further Reading:\n",
    "If you're interested, here are some studies that explore potential biases and confounders in chest xray datasets:\n",
    "* [Lauren Oakden-Rayner: Exploring the ChestXray14 dataset: problems](https://laurenoakdenrayner.com/2017/12/18/the-chestxray14-dataset-problems/)\n",
    "* [Amelia Jim√©nez-S√°nchez et al.: Detecting Shortcuts in Medical Images -- A Case Study in Chest X-rays](https://arxiv.org/abs/2211.04279)\n",
    "* [Judy Wawira Gichoya et al.: AI recognition of patient race in medical imaging: a modelling study](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00063-2/fulltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fairness assessment\n",
    "**Recap of Key Concepts**:\n",
    "\n",
    "In th class, we have learned:\n",
    "* The three key criteria for fairness assessment. What are they?\n",
    "- Independence - The same acteptence rate for all groups\n",
    "- Seperation - The same error for all groups\n",
    "- something? - the same score give same probability of acceptence for all groups??\n",
    "* Evaluation metrics corresponding to each criterion.\n",
    "* ROC curves.\n",
    "\n",
    "For this exercise, we‚Äôve provided a pre-trained ResNet classifier for Part 1, where the disease label is `Pneumothorax` and the sensitive attribute is `sex` (in metadata, you can get the binarized sex label from column `sex label`, where 0 represents female and 1 represents male). However, feel free to train your own model if you'd like.\n",
    "\n",
    "\n",
    "\n",
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(' device:', device)\n",
    "\n",
    "ds_name = 'NIH'\n",
    "\n",
    "# load the model\n",
    "lr=1e-6\n",
    "pretrained = True\n",
    "model_scale = '18'\n",
    "num_epochs =20\n",
    "img_size = (1, 224, 224)\n",
    "\n",
    "classifier = ResNet(num_classes=1, lr=lr, pretrained=pretrained, model_scale=model_scale, in_channel=img_size[0])\n",
    "classifier.load_state_dict(torch.load('./pretrained_model/nih_pneumothorax.pth'))\n",
    "classifier.to(device)\n",
    "\n",
    "classifier.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_at = './pretrained_models/'\n",
    "\n",
    "img_size = (1,224,224)\n",
    "batch_size = 16\n",
    "\n",
    "csv_pth = './datafiles/NIH_train_val_test_rs0_f50.csv' if ds_name == 'NIH' else None\n",
    "\n",
    "disease_label = 'Pneumothorax' \n",
    "sensitive_label = 'sex'\n",
    "augmentation = False\n",
    "\n",
    "from train.train_chestxray import create_datasets\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(dataset_pth, \n",
    "                                                               ds_name,\n",
    "                                                               csv_pth, \n",
    "                                                               image_size=img_size, \n",
    "                                                               device=device,\n",
    "                                                               disease_label = disease_label,\n",
    "                                                               sensitive_label = sensitive_label,\n",
    "                                                               augmentation=augmentation)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # we dont need it here\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the results for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lab, test_pred, test_prob, test_a= validate(classifier, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess fairness using Fairlearn\n",
    "#### A simple example first\n",
    "\n",
    "Fairlearn provides the `fairlearn.metrics.MetricFrame` class to help with this quantification. \n",
    "\n",
    "Given: \n",
    "<pre>\n",
    "y_true = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
    "sf_data = ['b', 'b', 'a', 'b', 'b', 'c', 'c', 'c', 'a',\n",
    "           'a', 'c', 'a', 'b', 'c', 'c', 'b', 'c', 'c']\n",
    "</pre>\n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./support4notebook/exercise_time.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try: \n",
    "* measure: recall, selection rate and false positive rate for *each group*;\n",
    "* plot the above result out; ([Hint](https://fairlearn.org/main/user_guide/assessment/plotting.html))\n",
    "* measure the difference in eqaulized odd between different groups;\n",
    "\n",
    "\n",
    "Hint: The documentation page of [MetricFrame](https://fairlearn.org/main/api_reference/generated/fairlearn.metrics.MetricFrame.html#fairlearn.metrics.MetricFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def NPV(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Extract the confusion matrix components\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "    return TN / (TN + FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame, selection_rate, count, false_positive_rate, true_positive_rate\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "y_true = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
    "sf_data = ['b', 'b', 'a', 'b', 'b', 'c', 'c', 'c', 'a',\n",
    "           'a', 'c', 'a', 'b', 'c', 'c', 'b', 'c', 'c']\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score, # Separation\n",
    "    'Negative Predictive Value (NPV)': NPV, #Sepatation\n",
    "    'false positive rate': false_positive_rate, # equalized odds\n",
    "    'true positive rate': true_positive_rate, # equalized odds, equalized opportunity  \n",
    "    'Independence(selection rate)': selection_rate,\n",
    "    'count': count\n",
    "    }\n",
    "metric_frame = MetricFrame(metrics=metrics,\n",
    "                           y_true=y_true,\n",
    "                           y_pred=y_pred,\n",
    "                           sensitive_features=sf_data)\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now measure the fairness metrics for our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./support4notebook/exercise.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MetricFrame(metrics=metrics,\n",
    "                 y_true=test_lab,\n",
    "                 y_pred=test_pred,\n",
    "                 sensitive_features=test_a)\n",
    "\n",
    "print(\"Test set fairness metrics (before mitigation):\")\n",
    "print(mf.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the ROC curve\n",
    "\n",
    "Here we provide the funtion `plot_roc_simple` to draw the ROC curve for each groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_simple(test_lab, test_prob, test_a, test_pred,\n",
    "        sensitive_attribute_name = 'sex',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí• Exercise and discusssion:\n",
    "* What do you see from the metrics and the ROC curve?\n",
    "* Try to measure and desribe the fairness wrt the 3 creterias we learned from class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bias mitigation using Fairlearn\n",
    "\n",
    "### Recall from the class\n",
    "* what kinds of mitigation methods have we learned?\n",
    "\n",
    "In this exercise, we will try to use the one pf the post-preprocessing bias mitiagtion method Fairlearn provided: **Threshold Optimization**, to implement the bias mitigation steps. \n",
    "\n",
    "### The theory of Threshold Optimization\n",
    "\n",
    "\n",
    "The idea could be simply visualized as below (figure from the [original paper](https://arxiv.org/pdf/1610.02413)):  \n",
    "![](./support4notebook/threshold_op.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where blue/green represent two sensitive groups, any points in the overlapping region meet the requirement of equalized odds:\n",
    "\n",
    "$$\n",
    "\\gamma_0(\\hat{Y}) = \\gamma_1(\\hat{Y}),\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\gamma_a (\\hat{Y}) = \\left(Pr(\\hat{Y} = 1 | A = a, Y = 0), Pr(\\hat{Y} = 1 | A = a, Y=1)\\right).\n",
    "$$\n",
    "\n",
    "The goal of the threshold optimizer is to find the point in the overlapping region that optimizes the objective function, such as balanced accuracy.\n",
    "\n",
    "To achieve this, **randomization** is introduced. The idea is starightforward: any point under the ROC curve can be estimated by weighting two points on the ROC curve (which could be achieved by simply thresholding); or in another word, a new decision threshold $T_a$ can be a randomized mixture of two decision thresholds $\\underline{t}_a$ and $\\overline{t}_a$.\n",
    "\n",
    "(See the figure below, which is from [this paper](https://arxiv.org/abs/2202.08536)).\n",
    "\n",
    "![Randomization Figure](./support4notebook/randomization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üìÉ Further Reading:\n",
    "* [Fairlearn *ThresholdOptimizier* page](https://fairlearn.org/v0.5.0/api_reference/fairlearn.postprocessing.html).\n",
    "* The original paper (See section 3): [Equality of opportunity in supervised learning](https://arxiv.org/pdf/1610.02413).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ Trick: A fake classifier class\n",
    "\n",
    "Fairlearn has some limitations when implementing the `ThresholdOptimizer` method. To work around these issues, a fake classifier is provided to bypass minor problems. If you use the provided classifier, this fake class should work just as well.\n",
    "\n",
    "However, if you're curious about what went wrong or want to use your own classifier, please read below:\n",
    "\n",
    "* **Problem 1: `estimator` in `ThresholdOptimizer` only accepts 2D input (tabular data).** This doesn‚Äôt make sense for post-processing mitigation methods, as the only relevant aspect here is the prediction scores from the test set. The classifier itself and the input data are irrelevant when optimizing the threshold.\n",
    "  \n",
    "* **Problem 2: The `prefit` parameter checks whether the model has been fitted in a simplistic way, leading to errors.** You can read more about this fit check function [here](https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_is_fitted.html).\n",
    "  \n",
    "* **Problem 3: It requires the prediction function to return scores for both classes in binary classification.** This might be an issue if your classifier only provides the probability for class 1.\n",
    "\n",
    "**How we solve this**: We create a fake classifier that accepts 2D input and reshapes it back to the original image size before feeding it into the prediction function. We trick the fit check by defining a fake variable and manually modify the output of the prediction function to include both classes if it only returns the probability for class 1.\n",
    "\n",
    "Note: If you trained your own classifier, you will need to implement a custom fake classifier yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class FakeClassifierInput2D(BaseEstimator,ClassifierMixin):\n",
    "    '''\n",
    "    Fake classifier that takes 2D input, with pre-trained model that does not take 2D input data\n",
    "    '''\n",
    "    def __init__(self,model, img_size):\n",
    "        self.model = model\n",
    "        self.img_size = img_size\n",
    "        self.input_from_2D_func = lambda x: torch.reshape(x,(-1,)+self.img_size)\n",
    "        # self.input_from_2D_func = input_from_2D_func\n",
    "        self.fit_ = True # fake the check_fit function inside the fairlearn library\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Do not need to fit\n",
    "        return\n",
    "\n",
    "    def predict(self, X_2D, ):\n",
    "        assert len(X_2D.shape) == 2\n",
    "        X = self.input_from_2D_func(X_2D)\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X_2D):\n",
    "        X = self.input_from_2D_func(X_2D)\n",
    "        return self.model.predict_proba(X)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, a_test = from_loader_to_tensor(test_loader,device)\n",
    "X_val, y_val, a_val = from_loader_to_tensor(val_loader,device)\n",
    "\n",
    "X_test_2D = torch.reshape(X_test,(X_test.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_fake = FakeClassifierInput2D(model=classifier.to('cpu'),\n",
    "                                       img_size = img_size,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the new threshold for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_simple(test_lab, test_prob, test_a, y_pred_fair_test,\n",
    "        sensitive_attribute_name = 'sex',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find out how the prediction come from (the new threshold $T_a$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "threshold_rules_by_group = to.interpolated_thresholder_.interpolation_dict\n",
    "print(json.dumps(threshold_rules_by_group, default=str, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí• Exercise and Discussion:\n",
    "* Can you write down the new threshold function? ([Hint](https://fairlearn.org/v0.10/user_guide/mitigation/postprocessing.html#postprocessing))\n",
    "* Compare the results. What do you observe, and does this model seem fair to you?\n",
    "* Hint: After optimization, you may notice that accuracy (or other metrics) is more balanced between groups. However, the overall accuracy (or other metrics of interest) may decrease for both groups. Do you think this is still a good or acceptable solution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./support4notebook/dilemma.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Potential pitfall: Algorithmic fairness in the presence of label noise\n",
    "As mentioned in class, it is easy to diagnose algorithmic bias. This is, however, only true if we have access to correct target labels for the test set. In this part of the project, we will simulate a situation where our test set ground truth target labels are incorrect in a biased way: You will simulate overdiagnosis among male individuals, by manually distorting some of their labels. Next, you will analyze how this affects the diagnosis and mitigation of algorithmic bias.\n",
    "\n",
    "## Write a script to distort the labels for the male individuals according to the following recipe:\n",
    "* Please create a new set of distorted target labels\n",
    "* Initialize these as identical to the supplied target labels\n",
    "* Manually distort them by flipping 30% of the healthy labels for male individuals to diseased. These should be selected at random.\n",
    "\n",
    "## Now repeat your analysis from Part 1 for your classifier from Part 1 using the distorted labels. \n",
    "You don‚Äôt need to retrain the classifier ‚Äì you will only repeat the diagnosis and mitigation parts.\n",
    "\n",
    "* Diagnose algorithmic bias with respect to your distorted labels. Do your conclusions change?\n",
    "* Mitigate algorithmic bias with respect to your distorted labels. Following this, repeat your diagnostic pipeline both with respect to your distorted and original labels. What do you see? Did mitigation ensure improved fairness with respect to the distorted labels? What happened with respect to the actual (original) labels? Is the mitigated algorithm actually fair?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./support4notebook/dataset.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_evrythin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
